{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "387600db-fcec-42d3-9023-64e4704f73d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /data/horse/ws/uskh580e-myws/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /data/horse/ws/uskh580e-myws/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /data/horse/ws/uskh580e-myws/nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace set up at: /data/horse/ws/uskh580e-myws\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from rank_bm25 import BM25Okapi\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from groq import Groq\n",
    "import time\n",
    "from datasets import load_dataset\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from rank_bm25 import BM25Okapi\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Define workspace path\n",
    "WORKSPACE_PATH = \"/data/horse/ws/uskh580e-myws\"\n",
    "\n",
    "# Set environment variables to store large files in workspace\n",
    "os.environ[\"HF_HOME\"] = os.path.join(WORKSPACE_PATH, \"huggingface\")\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = os.path.join(WORKSPACE_PATH, \"huggingface\")\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = os.path.join(WORKSPACE_PATH, \"datasets\")\n",
    "os.environ[\"NLTK_DATA\"] = os.path.join(WORKSPACE_PATH, \"nltk_data\")\n",
    "\n",
    "# Ensure necessary directories exist\n",
    "os.makedirs(os.environ[\"HF_HOME\"], exist_ok=True)\n",
    "os.makedirs(os.environ[\"TRANSFORMERS_CACHE\"], exist_ok=True)\n",
    "os.makedirs(os.environ[\"HF_DATASETS_CACHE\"], exist_ok=True)\n",
    "os.makedirs(os.environ[\"NLTK_DATA\"], exist_ok=True)\n",
    "BM25_INDEX_PATH = os.path.join(WORKSPACE_PATH, \"bm25_index.pkl\")\n",
    "WORKSPACE_PATH = \"/data/horse/ws/uskh580e-myws\"\n",
    "NLTK_PATH = os.path.join(WORKSPACE_PATH, \"nltk_data\")\n",
    "\n",
    "# Ensure directory exists\n",
    "os.makedirs(NLTK_PATH, exist_ok=True)\n",
    "\n",
    "# Set NLTK data path\n",
    "nltk.data.path.append(NLTK_PATH)\n",
    "\n",
    "# Force download punkt & stopwords\n",
    "nltk.download(\"punkt\", download_dir=NLTK_PATH, force=True)\n",
    "nltk.download(\"stopwords\", download_dir=NLTK_PATH, force=True)\n",
    "nltk.download(\"wordnet\", download_dir=NLTK_PATH, force=True)\n",
    "print(f\"Workspace set up at: {WORKSPACE_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48a9864f-f5bd-47cb-bd33-f750f3a47b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets loaded successfully and stored in: /data/horse/ws/uskh580e-myws/huggingface_datasets\n"
     ]
    }
   ],
   "source": [
    "DATASET_CACHE_DIR = os.path.join(WORKSPACE_PATH, \"huggingface_datasets\")\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(DATASET_CACHE_DIR, exist_ok=True)\n",
    "\n",
    "# Load datasets and store them in workspace cache\n",
    "query_data = load_dataset(\"princeton-nlp/LitSearch\", \"query\", split=\"full\", cache_dir=DATASET_CACHE_DIR)\n",
    "corpus_clean_data = load_dataset(\"princeton-nlp/LitSearch\", \"corpus_clean\", split=\"full\", cache_dir=DATASET_CACHE_DIR)\n",
    "corpus_s2orc_data = load_dataset(\"princeton-nlp/LitSearch\", \"corpus_s2orc\", split=\"full\", cache_dir=DATASET_CACHE_DIR)\n",
    "\n",
    "print(\"Datasets loaded successfully and stored in:\", DATASET_CACHE_DIR)\n",
    "query_df = query_data.to_pandas()\n",
    "corpus_clean_df = corpus_clean_data.to_pandas()\n",
    "corpus_s2orc_df = corpus_s2orc_data.to_pandas()\n",
    "corpus_df = corpus_clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3976e155-8d4e-4dc6-b2ca-e8c947a6ae88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BM25Retriever:\n",
    "    def __init__(self, corpus_df, text_column=\"abstract\", stopword_removal=True, use_stemming=True):\n",
    "        \"\"\"\n",
    "        BM25 Retriever for document retrieval.\n",
    "\n",
    "        Parameters:\n",
    "        - corpus_df: Pandas DataFrame containing the corpus\n",
    "        - text_column: Column in corpus_df that contains the text for retrieval\n",
    "        - stopword_removal: Whether to remove stopwords\n",
    "        - use_stemming: Whether to apply stemming\n",
    "        \"\"\"\n",
    "        self.corpus_df = corpus_df\n",
    "        self.text_column = text_column\n",
    "        self.stopword_removal = stopword_removal\n",
    "        self.use_stemming = use_stemming\n",
    "        self.bm25 = None\n",
    "        self.stemmer = PorterStemmer()\n",
    "        self.stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "    def tokenize_and_stem(self, text):\n",
    "        \"\"\" Tokenize, remove stopwords, and apply stemming (if enabled). \"\"\"\n",
    "        tokens = word_tokenize(text.lower())  # Tokenize & lowercase\n",
    "        if self.stopword_removal:\n",
    "            tokens = [token for token in tokens if token not in self.stop_words]  # Remove stopwords\n",
    "        if self.use_stemming:\n",
    "            tokens = [self.stemmer.stem(token) for token in tokens]  # Apply stemming\n",
    "        return tokens\n",
    "\n",
    "    def create_index(self):\n",
    "        \"\"\" Create BM25 index from the corpus. \"\"\"\n",
    "        print(\"Tokenizing and processing corpus...\")\n",
    "        self.corpus_df[\"tokens\"] = self.corpus_df[self.text_column].astype(str).apply(self.tokenize_and_stem)\n",
    "        self.bm25 = BM25Okapi(self.corpus_df[\"tokens\"].tolist())\n",
    "\n",
    "    def save_index(self, filename=BM25_INDEX_PATH):\n",
    "        \"\"\" Save BM25 index to workspace. \"\"\"\n",
    "        with open(filename, \"wb\") as f:\n",
    "            pickle.dump(self.bm25, f)\n",
    "        print(f\"BM25 index saved to {filename}\")\n",
    "\n",
    "    def load_index(self, filename=BM25_INDEX_PATH):\n",
    "        \"\"\" Load BM25 index from workspace. \"\"\"\n",
    "        with open(filename, \"rb\") as f:\n",
    "            self.bm25 = pickle.load(f)\n",
    "        print(f\"BM25 index loaded from {filename}\")\n",
    "\n",
    "    def retrieve(self, query, k=10):\n",
    "        \"\"\" Retrieve top-k documents for a query. \"\"\"\n",
    "        tokenized_query = self.tokenize_and_stem(query)\n",
    "        scores = self.bm25.get_scores(tokenized_query)\n",
    "        ranked_indices = np.argsort(scores)[::-1][:k]\n",
    "        return self.corpus_df.iloc[ranked_indices][\"corpusid\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db6aa321-43bc-4321-b550-ed7ca63c468c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loading existing BM25 index...\n",
      "BM25 index loaded from /data/horse/ws/uskh580e-myws/bm25_index.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running RAG with different retrievals per strategy: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 597/597 [49:25<00:00,  4.97s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>strategy</th>\n",
       "      <th>modified_query</th>\n",
       "      <th>retrieved_corpus_ids</th>\n",
       "      <th>retrieved</th>\n",
       "      <th>generated_answer</th>\n",
       "      <th>cited_corpus_ids</th>\n",
       "      <th>ground_truth_corpus_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Are there any research papers on methods to co...</td>\n",
       "      <td>zero-shot</td>\n",
       "      <td>Are there any research papers on methods to co...</td>\n",
       "      <td>[3643430, 257038997, 256461337, 235294276, 248...</td>\n",
       "      <td>[Deep learning networks have achieved state-of...</td>\n",
       "      <td>Yes, there are several research papers that fo...</td>\n",
       "      <td>[257038997, 248227350, 221995575, 234482764, 2...</td>\n",
       "      <td>[202719327]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Are there any research papers on methods to co...</td>\n",
       "      <td>few-shot</td>\n",
       "      <td>Here are examples of how to answer questions w...</td>\n",
       "      <td>[3643430, 257038997, 256461337, 235294276, 248...</td>\n",
       "      <td>[Deep learning networks have achieved state-of...</td>\n",
       "      <td>Yes, there are research papers on methods to c...</td>\n",
       "      <td>[257038997, 234482764, 219176798]</td>\n",
       "      <td>[202719327]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Are there any research papers on methods to co...</td>\n",
       "      <td>chain-of-thought</td>\n",
       "      <td>Let's break down the question step by step:\\n\\...</td>\n",
       "      <td>[3643430, 257038997, 256461337, 235294276, 248...</td>\n",
       "      <td>[Deep learning networks have achieved state-of...</td>\n",
       "      <td>To answer the question, let's break it down st...</td>\n",
       "      <td>[257038997, 248227350, 221995575, 234482764]</td>\n",
       "      <td>[202719327]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Are there any resources available for translat...</td>\n",
       "      <td>zero-shot</td>\n",
       "      <td>Are there any resources available for translat...</td>\n",
       "      <td>[199379793, 227231792, 16825250, 15225095, 252...</td>\n",
       "      <td>[Parallel corpora available for building machi...</td>\n",
       "      <td>Based on the retrieved documents, there are se...</td>\n",
       "      <td>[227231792, 16825250, 233365022]</td>\n",
       "      <td>[227231792]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Are there any resources available for translat...</td>\n",
       "      <td>few-shot</td>\n",
       "      <td>Here are examples of how to answer questions w...</td>\n",
       "      <td>[199379793, 227231792, 16825250, 15225095, 252...</td>\n",
       "      <td>[Parallel corpora available for building machi...</td>\n",
       "      <td>Yes, there are resources available for transla...</td>\n",
       "      <td>[227231792, 233365022, 16563009]</td>\n",
       "      <td>[227231792]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786</th>\n",
       "      <td>What paper provides generalization bounds for ...</td>\n",
       "      <td>few-shot</td>\n",
       "      <td>Here are examples of how to answer questions w...</td>\n",
       "      <td>[238582773, 257482844, 254247299, 248118561, 2...</td>\n",
       "      <td>[Recently, large-scale Contrastive Language-Im...</td>\n",
       "      <td>According to the retrieved documents, specific...</td>\n",
       "      <td>[238582773, 254247299, 247447209]</td>\n",
       "      <td>[263830433]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1787</th>\n",
       "      <td>What paper provides generalization bounds for ...</td>\n",
       "      <td>chain-of-thought</td>\n",
       "      <td>Let's break down the question step by step:\\n\\...</td>\n",
       "      <td>[238582773, 257482844, 254247299, 248118561, 2...</td>\n",
       "      <td>[Recently, large-scale Contrastive Language-Im...</td>\n",
       "      <td>Based on the retrieved documents, I found no s...</td>\n",
       "      <td>[257482844, 254247299, 247447209]</td>\n",
       "      <td>[263830433]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1788</th>\n",
       "      <td>Which paper systematically examed the input mi...</td>\n",
       "      <td>zero-shot</td>\n",
       "      <td>Which paper systematically examed the input mi...</td>\n",
       "      <td>[256390009, 261276856, 261682404, 247763065, 2...</td>\n",
       "      <td>[We explore the problem of generating minority...</td>\n",
       "      <td>The paper that systematically examined the inp...</td>\n",
       "      <td>[261276856]</td>\n",
       "      <td>[261276856]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1789</th>\n",
       "      <td>Which paper systematically examed the input mi...</td>\n",
       "      <td>few-shot</td>\n",
       "      <td>Here are examples of how to answer questions w...</td>\n",
       "      <td>[256390009, 261276856, 261682404, 247763065, 2...</td>\n",
       "      <td>[We explore the problem of generating minority...</td>\n",
       "      <td>Answer: The paper that systematically examined...</td>\n",
       "      <td>[261276856]</td>\n",
       "      <td>[261276856]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1790</th>\n",
       "      <td>Which paper systematically examed the input mi...</td>\n",
       "      <td>chain-of-thought</td>\n",
       "      <td>Let's break down the question step by step:\\n\\...</td>\n",
       "      <td>[256390009, 261276856, 261682404, 247763065, 2...</td>\n",
       "      <td>[We explore the problem of generating minority...</td>\n",
       "      <td>After processing the query, I found the releva...</td>\n",
       "      <td>[261276856]</td>\n",
       "      <td>[261276856]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1791 rows √ó 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  query          strategy  \\\n",
       "0     Are there any research papers on methods to co...         zero-shot   \n",
       "1     Are there any research papers on methods to co...          few-shot   \n",
       "2     Are there any research papers on methods to co...  chain-of-thought   \n",
       "3     Are there any resources available for translat...         zero-shot   \n",
       "4     Are there any resources available for translat...          few-shot   \n",
       "...                                                 ...               ...   \n",
       "1786  What paper provides generalization bounds for ...          few-shot   \n",
       "1787  What paper provides generalization bounds for ...  chain-of-thought   \n",
       "1788  Which paper systematically examed the input mi...         zero-shot   \n",
       "1789  Which paper systematically examed the input mi...          few-shot   \n",
       "1790  Which paper systematically examed the input mi...  chain-of-thought   \n",
       "\n",
       "                                         modified_query  \\\n",
       "0     Are there any research papers on methods to co...   \n",
       "1     Here are examples of how to answer questions w...   \n",
       "2     Let's break down the question step by step:\\n\\...   \n",
       "3     Are there any resources available for translat...   \n",
       "4     Here are examples of how to answer questions w...   \n",
       "...                                                 ...   \n",
       "1786  Here are examples of how to answer questions w...   \n",
       "1787  Let's break down the question step by step:\\n\\...   \n",
       "1788  Which paper systematically examed the input mi...   \n",
       "1789  Here are examples of how to answer questions w...   \n",
       "1790  Let's break down the question step by step:\\n\\...   \n",
       "\n",
       "                                   retrieved_corpus_ids  \\\n",
       "0     [3643430, 257038997, 256461337, 235294276, 248...   \n",
       "1     [3643430, 257038997, 256461337, 235294276, 248...   \n",
       "2     [3643430, 257038997, 256461337, 235294276, 248...   \n",
       "3     [199379793, 227231792, 16825250, 15225095, 252...   \n",
       "4     [199379793, 227231792, 16825250, 15225095, 252...   \n",
       "...                                                 ...   \n",
       "1786  [238582773, 257482844, 254247299, 248118561, 2...   \n",
       "1787  [238582773, 257482844, 254247299, 248118561, 2...   \n",
       "1788  [256390009, 261276856, 261682404, 247763065, 2...   \n",
       "1789  [256390009, 261276856, 261682404, 247763065, 2...   \n",
       "1790  [256390009, 261276856, 261682404, 247763065, 2...   \n",
       "\n",
       "                                              retrieved  \\\n",
       "0     [Deep learning networks have achieved state-of...   \n",
       "1     [Deep learning networks have achieved state-of...   \n",
       "2     [Deep learning networks have achieved state-of...   \n",
       "3     [Parallel corpora available for building machi...   \n",
       "4     [Parallel corpora available for building machi...   \n",
       "...                                                 ...   \n",
       "1786  [Recently, large-scale Contrastive Language-Im...   \n",
       "1787  [Recently, large-scale Contrastive Language-Im...   \n",
       "1788  [We explore the problem of generating minority...   \n",
       "1789  [We explore the problem of generating minority...   \n",
       "1790  [We explore the problem of generating minority...   \n",
       "\n",
       "                                       generated_answer  \\\n",
       "0     Yes, there are several research papers that fo...   \n",
       "1     Yes, there are research papers on methods to c...   \n",
       "2     To answer the question, let's break it down st...   \n",
       "3     Based on the retrieved documents, there are se...   \n",
       "4     Yes, there are resources available for transla...   \n",
       "...                                                 ...   \n",
       "1786  According to the retrieved documents, specific...   \n",
       "1787  Based on the retrieved documents, I found no s...   \n",
       "1788  The paper that systematically examined the inp...   \n",
       "1789  Answer: The paper that systematically examined...   \n",
       "1790  After processing the query, I found the releva...   \n",
       "\n",
       "                                       cited_corpus_ids  \\\n",
       "0     [257038997, 248227350, 221995575, 234482764, 2...   \n",
       "1                     [257038997, 234482764, 219176798]   \n",
       "2          [257038997, 248227350, 221995575, 234482764]   \n",
       "3                      [227231792, 16825250, 233365022]   \n",
       "4                      [227231792, 233365022, 16563009]   \n",
       "...                                                 ...   \n",
       "1786                  [238582773, 254247299, 247447209]   \n",
       "1787                  [257482844, 254247299, 247447209]   \n",
       "1788                                        [261276856]   \n",
       "1789                                        [261276856]   \n",
       "1790                                        [261276856]   \n",
       "\n",
       "     ground_truth_corpus_ids  \n",
       "0                [202719327]  \n",
       "1                [202719327]  \n",
       "2                [202719327]  \n",
       "3                [227231792]  \n",
       "4                [227231792]  \n",
       "...                      ...  \n",
       "1786             [263830433]  \n",
       "1787             [263830433]  \n",
       "1788             [261276856]  \n",
       "1789             [261276856]  \n",
       "1790             [261276856]  \n",
       "\n",
       "[1791 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from groq import Groq\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Initialize BM25 Retriever\n",
    "bm25_retriever = BM25Retriever(corpus_df)\n",
    "\n",
    "# ‚úÖ Ensure BM25 index is loaded or created\n",
    "if os.path.exists(BM25_INDEX_PATH):\n",
    "    print(\"‚úÖ Loading existing BM25 index...\")\n",
    "    bm25_retriever.load_index(BM25_INDEX_PATH)\n",
    "\n",
    "# If BM25 index is still None, create it\n",
    "if bm25_retriever.bm25 is None:\n",
    "    print(\"‚ö†Ô∏è BM25 index not found, creating a new index...\")\n",
    "    bm25_retriever.create_index()\n",
    "    bm25_retriever.save_index(BM25_INDEX_PATH)\n",
    "\n",
    "\n",
    "# Initialize Groq API client\n",
    "groq_client = Groq(api_key=\"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\")\n",
    "\n",
    "def reformulate_query(query, strategy):\n",
    "    \"\"\" Reformulates the query only for LLM input, not for retrieval. \"\"\"\n",
    "    if strategy == \"zero-shot\":\n",
    "        return query  # No modification, use as-is.\n",
    "\n",
    "    elif strategy == \"few-shot\":\n",
    "        return f\"\"\"Here are examples of how to answer questions while citing sources from retrieved documents.\n",
    "\n",
    "        Example 1:\n",
    "        Question: How do transformer models compare to LSTMs?\n",
    "        Answer: Transformer models outperform LSTMs due to their ability to capture long-range dependencies. \n",
    "        (Source: \"Transformer Models for NLP\", Corpus ID: 12345)\n",
    "\n",
    "        Example 2:\n",
    "        Question: What is the role of reinforcement learning in AI?\n",
    "        Answer: Reinforcement learning is widely used in robotics, game playing, and automated control tasks. \n",
    "        (Source: \"Reinforcement Learning in AI Applications\", Corpus ID: 67890)\n",
    "\n",
    "        Example 3:\n",
    "        Question: How effective are BERT embeddings for document retrieval?\n",
    "        Answer: BERT embeddings improve retrieval performance by encoding semantic similarity, outperforming traditional TF-IDF methods.\n",
    "        (Source: \"Advancements in Document Retrieval using BERT\", Corpus ID: 11223)\n",
    "\n",
    "        Now, using the retrieved documents below, answer the question while citing sources explicitly:\n",
    "        {query}\"\"\"\n",
    "\n",
    "    elif strategy == \"chain-of-thought\":\n",
    "        return f\"\"\"Let's break down the question step by step:\n",
    "\n",
    "        Step 1: Identify key concepts and entities in the question.\n",
    "        Step 2: Search for relevant supporting evidence from retrieved documents.\n",
    "        Step 3: Construct an answer using the evidence while explicitly citing the relevant document IDs.\n",
    "\n",
    "        Now, process this query:\n",
    "        {query}\"\"\"\n",
    "\n",
    "\n",
    "def generate_with_rag(original_query, modified_query, retrieved_corpus_ids, retrieved_titles, retrieved_texts):\n",
    "    \"\"\" Generates an answer using RAG, keeping retrieval separate from query modification. \"\"\"\n",
    "    context = \"\\n\".join([\n",
    "        f\"Document ID: {doc_id}\\nTitle: {title}\\nFull Text: {full_text}\"\n",
    "        for doc_id, title, full_text in zip(retrieved_corpus_ids, retrieved_titles, retrieved_texts)\n",
    "    ])\n",
    "\n",
    "    prompt = f\"\"\"Use the following retrieved documents to answer the question.\n",
    "\n",
    "    Retrieved Documents:\n",
    "    {context}\n",
    "\n",
    "    Question: {modified_query}\n",
    "    Answer:\"\"\"\n",
    "\n",
    "    response = groq_client.chat.completions.create(\n",
    "        model=\"llama3-8b-8192\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an AI that generates well-supported answers using retrieved documents.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content  # Return the generated answer\n",
    "\n",
    "\n",
    "# Ensure `query_df` has ground-truth corpus IDs stored as lists\n",
    "query_df[\"corpusids\"] = query_df[\"corpusids\"].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "\n",
    "# Use the entire dataset for retrieval\n",
    "query_sample_df = query_df\n",
    "\n",
    "# ‚úÖ **Run RAG without altering the retrieval query**\n",
    "rag_results = []\n",
    "\n",
    "for _, row in tqdm(query_sample_df.iterrows(), total=len(query_sample_df), desc=\"Running RAG with different retrievals per strategy\"):\n",
    "    original_query = row[\"query\"]\n",
    "    ground_truth_corpus_ids = row[\"corpusids\"]  # Retrieve the ground-truth relevant corpus IDs\n",
    "\n",
    "    # **Retrieve using the original query (NO query modification before retrieval)**\n",
    "    retrieved_ids = bm25_retriever.retrieve(original_query, k=10)\n",
    "    \n",
    "    # Fetch retrieved document details\n",
    "    ranked_retrieved_df = pd.DataFrame({\"corpusid\": retrieved_ids})\n",
    "    retrieved_docs_info = ranked_retrieved_df.merge(\n",
    "        corpus_df[[\"corpusid\", \"title\", \"abstract\"]], \n",
    "        on=\"corpusid\", \n",
    "        how=\"left\"\n",
    "    )\n",
    "    retrieved_corpus_ids = retrieved_docs_info[\"corpusid\"].tolist()\n",
    "    retrieved_titles = retrieved_docs_info[\"title\"].tolist()\n",
    "    retrieved_abstracts = retrieved_docs_info[\"abstract\"].tolist()\n",
    "\n",
    "    # ‚úÖ **Now apply different prompting strategies (AFTER retrieval)**\n",
    "    for strategy in [\"zero-shot\", \"few-shot\", \"chain-of-thought\"]:\n",
    "        modified_query = reformulate_query(original_query, strategy)\n",
    "\n",
    "        # Generate answer using the modified query (but retrieved docs stay the same)\n",
    "        generated_answer = generate_with_rag(original_query, modified_query, retrieved_corpus_ids, retrieved_titles, retrieved_abstracts)\n",
    "\n",
    "        # Identify which corpus IDs are actually cited in the answer\n",
    "        cited_corpus_ids = [str(doc_id) for doc_id in retrieved_corpus_ids if str(doc_id) in generated_answer]\n",
    "\n",
    "        # Store results\n",
    "        rag_results.append({\n",
    "            \"query\": original_query,\n",
    "            \"strategy\": strategy,\n",
    "            \"modified_query\": modified_query,\n",
    "            \"retrieved_corpus_ids\": retrieved_corpus_ids,  # Documents retrieved by BM25\n",
    "            \"retrieved\": retrieved_abstracts,  # Full text of retrieved documents\n",
    "            \"generated_answer\": generated_answer,\n",
    "            \"cited_corpus_ids\": cited_corpus_ids,  # Docs explicitly mentioned in the answer\n",
    "            \"ground_truth_corpus_ids\": ground_truth_corpus_ids  # Actual relevant corpus IDs\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame\n",
    "rag_results_df = pd.DataFrame(rag_results)\n",
    "\n",
    "# Save results to workspace\n",
    "RAG_RESULTS_PATH = os.path.join(WORKSPACE_PATH, \"rag_results_no_query_change.csv\")\n",
    "rag_results_df.to_csv(RAG_RESULTS_PATH, index=False)\n",
    "display(rag_results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa3d1099-9ecc-45a3-a424-1815f2b66673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Strategy</th>\n",
       "      <th>Recall@5</th>\n",
       "      <th>Recall@20</th>\n",
       "      <th>Citation Precision</th>\n",
       "      <th>Citation Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zero-shot</td>\n",
       "      <td>0.25215</td>\n",
       "      <td>0.457398</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>few-shot</td>\n",
       "      <td>0.25215</td>\n",
       "      <td>0.457398</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chain-of-thought</td>\n",
       "      <td>0.25215</td>\n",
       "      <td>0.457398</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Strategy  Recall@5  Recall@20  Citation Precision  Citation Recall\n",
       "0         zero-shot   0.25215   0.457398                 0.0              0.0\n",
       "1          few-shot   0.25215   0.457398                 0.0              0.0\n",
       "2  chain-of-thought   0.25215   0.457398                 0.0              0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def compute_metrics(df):\n",
    "    metrics = []\n",
    "    \n",
    "    for strategy in df[\"strategy\"].unique():\n",
    "        subset = df[df[\"strategy\"] == strategy]\n",
    "\n",
    "        recall_5 = subset.apply(lambda row: len(set(row[\"retrieved_corpus_ids\"][:5]) & set(row[\"ground_truth_corpus_ids\"])) / len(row[\"ground_truth_corpus_ids\"]) if len(row[\"ground_truth_corpus_ids\"]) > 0 else 0, axis=1).mean()\n",
    "        recall_20 = subset.apply(lambda row: len(set(row[\"retrieved_corpus_ids\"][:20]) & set(row[\"ground_truth_corpus_ids\"])) / len(row[\"ground_truth_corpus_ids\"]) if len(row[\"ground_truth_corpus_ids\"]) > 0 else 0, axis=1).mean()\n",
    "        citation_precision = subset.apply(lambda row: len(set(row[\"cited_corpus_ids\"]) & set(row[\"ground_truth_corpus_ids\"])) / len(row[\"cited_corpus_ids\"]) if len(row[\"cited_corpus_ids\"]) > 0 else 0, axis=1).mean()\n",
    "        citation_recall = subset.apply(lambda row: len(set(row[\"cited_corpus_ids\"]) & set(row[\"ground_truth_corpus_ids\"])) / len(row[\"ground_truth_corpus_ids\"]) if len(row[\"ground_truth_corpus_ids\"]) > 0 else 0, axis=1).mean()\n",
    "\n",
    "        metrics.append({\n",
    "            \"Strategy\": strategy,\n",
    "            \"Recall@5\": recall_5,\n",
    "            \"Recall@20\": recall_20,\n",
    "            \"Citation Precision\": citation_precision,\n",
    "            \"Citation Recall\": citation_recall\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(metrics)\n",
    "\n",
    "# Compute and display the metrics\n",
    "metrics_df = compute_metrics(rag_results_df)\n",
    "display(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec44090e-7647-461b-b114-207f7c60aa84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strategy</th>\n",
       "      <th>Recall@5</th>\n",
       "      <th>Recall@20</th>\n",
       "      <th>Citation Precision</th>\n",
       "      <th>Citation Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chain-of-thought</td>\n",
       "      <td>0.25215</td>\n",
       "      <td>0.457398</td>\n",
       "      <td>0.218511</td>\n",
       "      <td>0.371413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>few-shot</td>\n",
       "      <td>0.25215</td>\n",
       "      <td>0.457398</td>\n",
       "      <td>0.251035</td>\n",
       "      <td>0.357677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zero-shot</td>\n",
       "      <td>0.25215</td>\n",
       "      <td>0.457398</td>\n",
       "      <td>0.237935</td>\n",
       "      <td>0.345449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           strategy  Recall@5  Recall@20  Citation Precision  Citation Recall\n",
       "0  chain-of-thought   0.25215   0.457398            0.218511         0.371413\n",
       "1          few-shot   0.25215   0.457398            0.251035         0.357677\n",
       "2         zero-shot   0.25215   0.457398            0.237935         0.345449"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# ‚úÖ Ensure lists are properly formatted and contain only strings\n",
    "for col in [\"retrieved_corpus_ids\", \"ground_truth_corpus_ids\", \"cited_corpus_ids\"]:\n",
    "    rag_results_df[col] = rag_results_df[col].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "    rag_results_df[col] = rag_results_df[col].apply(lambda x: list(map(str, x)) if isinstance(x, list) else [])\n",
    "\n",
    "# ‚úÖ Compute all retrieval and citation metrics\n",
    "def compute_metrics(row):\n",
    "    retrieved_corpus_ids = set(row[\"retrieved_corpus_ids\"][:20])  # Ensure only top-20 retrieved\n",
    "    ground_truth_corpus_ids = set(row[\"ground_truth_corpus_ids\"])\n",
    "    cited_corpus_ids = set(row[\"cited_corpus_ids\"])\n",
    "\n",
    "    tp_retrieved_5 = len(set(row[\"retrieved_corpus_ids\"][:5]) & ground_truth_corpus_ids)\n",
    "    tp_retrieved_20 = len(retrieved_corpus_ids & ground_truth_corpus_ids)\n",
    "    tp_cited = len(cited_corpus_ids & ground_truth_corpus_ids)\n",
    "\n",
    "    recall_5 = tp_retrieved_5 / len(ground_truth_corpus_ids) if len(ground_truth_corpus_ids) > 0 else 0.0\n",
    "    recall_20 = tp_retrieved_20 / len(ground_truth_corpus_ids) if len(ground_truth_corpus_ids) > 0 else 0.0\n",
    "    citation_precision = tp_cited / len(cited_corpus_ids) if len(cited_corpus_ids) > 0 else 0.0\n",
    "    citation_recall = tp_cited / len(ground_truth_corpus_ids) if len(ground_truth_corpus_ids) > 0 else 0.0\n",
    "\n",
    "    return pd.Series([recall_5, recall_20, citation_precision, citation_recall], \n",
    "                     index=[\"Recall@5\", \"Recall@20\", \"Citation Precision\", \"Citation Recall\"])\n",
    "\n",
    "# ‚úÖ Apply function\n",
    "rag_results_df[[\"Recall@5\", \"Recall@20\", \"Citation Precision\", \"Citation Recall\"]] = rag_results_df.apply(compute_metrics, axis=1)\n",
    "\n",
    "# ‚úÖ Aggregate metrics per strategy\n",
    "metrics_summary = rag_results_df.groupby(\"strategy\")[\n",
    "    [\"Recall@5\", \"Recall@20\", \"Citation Precision\", \"Citation Recall\"]\n",
    "].mean().reset_index()\n",
    "\n",
    "# ‚úÖ Display final table\n",
    "display(metrics_summary)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96b2523f-3834-403f-a947-f40b69aaf505",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/horse/ws/uskh580e-llm_citation_ws/myenv/lib/python3.10/site-packages/transformers/utils/hub.py:106: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52b5f5fd-4aba-4f81-ab7d-9a700d78c0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2794f42d-e833-4b58-bb2b-96d37c54e96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gritlm import GritLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5dfc4fff-43e0-4904-84fd-e4360b249986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define workspace path\n",
    "WORKSPACE_PATH = \"/data/horse/ws/uskh580e-myws\"\n",
    "os.makedirs(WORKSPACE_PATH, exist_ok=True)\n",
    "\n",
    "# ‚úÖ Define paths for saving/retrieving cached embeddings\n",
    "E5_INDEX_PATH = os.path.join(WORKSPACE_PATH, \"e5_index.pkl\")\n",
    "GTR_INDEX_PATH = os.path.join(WORKSPACE_PATH, \"gtr_index.pkl\")\n",
    "GRIT_INDEX_PATH = os.path.join(WORKSPACE_PATH, \"grit_index.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d676488f-df9a-4f05-ac80-0f9132cb330f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded cached E5 embeddings\n"
     ]
    }
   ],
   "source": [
    "class E5Retriever:\n",
    "    def __init__(self, corpus_df):\n",
    "        self.corpus_df = corpus_df\n",
    "        self.model = SentenceTransformer(\"intfloat/e5-large-v2\", device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.embeddings = None\n",
    "        self._prepare_embeddings()\n",
    "\n",
    "    def _prepare_embeddings(self):\n",
    "        \"\"\"Compute and save E5 embeddings if not cached.\"\"\"\n",
    "        if self._try_load_cache():\n",
    "            return\n",
    "\n",
    "        print(\"üîÑ Computing E5 embeddings...\")\n",
    "        texts = [\"passage: \" + text for text in self.corpus_df[\"abstract\"].astype(str)]\n",
    "        self.embeddings = self.model.encode(texts, batch_size=256, normalize_embeddings=True, show_progress_bar=True)\n",
    "        self._save_cache()\n",
    "\n",
    "    def _try_load_cache(self):\n",
    "        \"\"\"Load cached embeddings if available.\"\"\"\n",
    "        if os.path.exists(E5_INDEX_PATH):\n",
    "            try:\n",
    "                with open(E5_INDEX_PATH, \"rb\") as f:\n",
    "                    self.embeddings = pickle.load(f)\n",
    "                    print(\"‚úÖ Loaded cached E5 embeddings\")\n",
    "                    return True\n",
    "            except:\n",
    "                print(\"‚ö†Ô∏è Failed to load cache.\")\n",
    "        return False\n",
    "\n",
    "    def _save_cache(self):\n",
    "        \"\"\"Save embeddings to cache.\"\"\"\n",
    "        with open(E5_INDEX_PATH, \"wb\") as f:\n",
    "            pickle.dump(self.embeddings, f)\n",
    "\n",
    "    def retrieve(self, query, k=10):\n",
    "        \"\"\"Retrieve top-k documents for a query.\"\"\"\n",
    "        query_embedding = self.model.encode([\"query: \" + query], normalize_embeddings=True)\n",
    "        scores = np.dot(query_embedding, self.embeddings.T)\n",
    "        ranked_indices = np.argsort(-scores[0])[:k]\n",
    "        return self.corpus_df.iloc[ranked_indices][\"corpusid\"].tolist()\n",
    "\n",
    "# ‚úÖ **Ensure Retrieval Occurs Before Query Reformulation**\n",
    "e5_retriever = E5Retriever(corpus_df)\n",
    "\n",
    "if e5_retriever.embeddings is None:\n",
    "    print(\"‚ö†Ô∏è E5 embeddings not found, computing...\")\n",
    "    e5_retriever._prepare_embeddings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5f54148-8924-4cee-9cad-0d9f3ad807cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded cached GTR embeddings\n"
     ]
    }
   ],
   "source": [
    "class GTRRetriever:\n",
    "    def __init__(self, corpus_df):\n",
    "        self.corpus_df = corpus_df\n",
    "        self.model = SentenceTransformer(\"sentence-transformers/gtr-t5-large\", device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.embeddings = None\n",
    "        self._prepare_embeddings()\n",
    "\n",
    "    def _prepare_embeddings(self):\n",
    "        \"\"\"Compute and save GTR embeddings if not cached.\"\"\"\n",
    "        if self._try_load_cache():\n",
    "            return\n",
    "        \n",
    "        print(\"üîÑ Computing GTR embeddings...\")\n",
    "        texts = self.corpus_df[\"abstract\"].astype(str)\n",
    "        self.embeddings = self.model.encode(texts, batch_size=256, convert_to_numpy=True, show_progress_bar=True)\n",
    "        self._save_cache()\n",
    "\n",
    "    def _try_load_cache(self):\n",
    "        \"\"\"Load cached embeddings if available.\"\"\"\n",
    "        if os.path.exists(GTR_INDEX_PATH):\n",
    "            try:\n",
    "                with open(GTR_INDEX_PATH, \"rb\") as f:\n",
    "                    self.embeddings = pickle.load(f)\n",
    "                    print(\"‚úÖ Loaded cached GTR embeddings\")\n",
    "                    return True\n",
    "            except:\n",
    "                print(\"‚ö†Ô∏è Failed to load cache.\")\n",
    "        return False\n",
    "\n",
    "    def _save_cache(self):\n",
    "        \"\"\"Save embeddings to cache.\"\"\"\n",
    "        with open(GTR_INDEX_PATH, \"wb\") as f:\n",
    "            pickle.dump(self.embeddings, f)\n",
    "\n",
    "    def retrieve(self, query, k=10):\n",
    "        \"\"\"Retrieve top-k documents for a query.\"\"\"\n",
    "        query_embedding = self.model.encode([query], convert_to_numpy=True)\n",
    "        scores = query_embedding @ self.embeddings.T\n",
    "        ranked_indices = np.argsort(-scores[0])[:k]\n",
    "        return self.corpus_df.iloc[ranked_indices][\"corpusid\"].tolist()\n",
    "\n",
    "# ‚úÖ **Ensure Retrieval Occurs Before Query Reformulation**\n",
    "gtr_retriever = GTRRetriever(corpus_df)\n",
    "\n",
    "if gtr_retriever.embeddings is None:\n",
    "    print(\"‚ö†Ô∏è GTR embeddings not found, computing...\")\n",
    "    gtr_retriever._prepare_embeddings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8eeb8b22-fdb0-4b58-a2ae-9042d8fa3828",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/GritLM/GritLM-7B:\n",
      "- modeling_gritlm7b.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88e86fdba30943ba8963ed4610e57cc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created GritLM: torch.bfloat16 dtype, mean pool, embedding mode, bbcc attn\n",
      "‚úÖ Loaded cached GRIT embeddings\n"
     ]
    }
   ],
   "source": [
    "class GRITRetriever:\n",
    "    def __init__(self, corpus_df):\n",
    "        self.corpus_df = corpus_df\n",
    "        self.model = GritLM(\"GritLM/GritLM-7B\", device_map=\"auto\", torch_dtype=torch.bfloat16, mode=\"embedding\")\n",
    "        self.embeddings = None\n",
    "        self._prepare_embeddings()\n",
    "\n",
    "    def _prepare_embeddings(self):\n",
    "        \"\"\"Compute and save GRITLM embeddings if not cached.\"\"\"\n",
    "        if self._try_load_cache():\n",
    "            return\n",
    "\n",
    "        print(\"üîÑ Computing GRIT embeddings...\")\n",
    "        texts = [f\"<|embed|>\\n{text}\" for text in self.corpus_df[\"abstract\"].astype(str)]\n",
    "        self.embeddings = self.model.encode(texts, batch_size=128, convert_to_numpy=True, show_progress_bar=True)\n",
    "        self._save_cache()\n",
    "\n",
    "    def _try_load_cache(self):\n",
    "        \"\"\"Load cached embeddings if available.\"\"\"\n",
    "        if os.path.exists(GRIT_INDEX_PATH):\n",
    "            try:\n",
    "                with open(GRIT_INDEX_PATH, \"rb\") as f:\n",
    "                    self.embeddings = pickle.load(f)\n",
    "                    print(\"‚úÖ Loaded cached GRIT embeddings\")\n",
    "                    return True\n",
    "            except:\n",
    "                print(\"‚ö†Ô∏è Failed to load cache.\")\n",
    "        return False\n",
    "\n",
    "    def _save_cache(self):\n",
    "        \"\"\"Save embeddings to cache.\"\"\"\n",
    "        with open(GRIT_INDEX_PATH, \"wb\") as f:\n",
    "            pickle.dump(self.embeddings, f)\n",
    "\n",
    "    def retrieve(self, query, k=10):\n",
    "        \"\"\"Retrieve top-k documents for a query.\"\"\"\n",
    "        formatted_query = f\"<|user|>\\nRepresent this query for retrieving relevant documents:\\n<|embed|>\\n{query}\"\n",
    "        query_embedding = self.model.encode([formatted_query], convert_to_numpy=True)\n",
    "        scores = query_embedding @ self.embeddings.T\n",
    "        ranked_indices = np.argsort(-scores[0])[:k]\n",
    "        return self.corpus_df.iloc[ranked_indices][\"corpusid\"].tolist()\n",
    "\n",
    "# ‚úÖ **Ensure Retrieval Occurs Before Query Reformulation**\n",
    "grit_retriever = GRITRetriever(corpus_df)\n",
    "\n",
    "if grit_retriever.embeddings is None:\n",
    "    print(\"‚ö†Ô∏è GRITLM embeddings not found, computing...\")\n",
    "    grit_retriever._prepare_embeddings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "40264dd7-7661-40e0-9c29-f98effc7c908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Running Retrieval with E5 on 10% dataset...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving with E5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 60/60 [05:08<00:00,  5.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Running Retrieval with GTR on 10% dataset...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving with GTR: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 60/60 [05:14<00:00,  5.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Running Retrieval with GRITLM on 10% dataset...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving with GRITLM: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 60/60 [05:28<00:00,  5.47s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Retriever</th>\n",
       "      <th>Query</th>\n",
       "      <th>Strategy</th>\n",
       "      <th>Retrieved Corpus IDs</th>\n",
       "      <th>Retrieved Abstracts</th>\n",
       "      <th>Generated Answer</th>\n",
       "      <th>Cited Corpus IDs</th>\n",
       "      <th>Ground Truth Corpus IDs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E5</td>\n",
       "      <td>Can you recommend research that uses an LLM to...</td>\n",
       "      <td>zero-shot</td>\n",
       "      <td>[258041372, 252716013, 260125086, 253098700, 2...</td>\n",
       "      <td>[Current literature demonstrates that Large La...</td>\n",
       "      <td>Based on the retrieved documents, here are som...</td>\n",
       "      <td>[252716013, 253098700, 264426355, 252596001, 2...</td>\n",
       "      <td>[229923710]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E5</td>\n",
       "      <td>Can you recommend research that uses an LLM to...</td>\n",
       "      <td>few-shot</td>\n",
       "      <td>[258041372, 252716013, 260125086, 253098700, 2...</td>\n",
       "      <td>[Current literature demonstrates that Large La...</td>\n",
       "      <td>According to the retrieved documents, a resear...</td>\n",
       "      <td>[261696510, 248986239, 258558102]</td>\n",
       "      <td>[229923710]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E5</td>\n",
       "      <td>Can you recommend research that uses an LLM to...</td>\n",
       "      <td>chain-of-thought</td>\n",
       "      <td>[258041372, 252716013, 260125086, 253098700, 2...</td>\n",
       "      <td>[Current literature demonstrates that Large La...</td>\n",
       "      <td>Here's the breakdown of the question step by s...</td>\n",
       "      <td>[258041372, 252716013, 260125086, 253098700, 2...</td>\n",
       "      <td>[229923710]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E5</td>\n",
       "      <td>Which paper proposed decomposing the logit upd...</td>\n",
       "      <td>zero-shot</td>\n",
       "      <td>[254926669, 253761014, 247315171, 182953113, 1...</td>\n",
       "      <td>[Transformer-based large language models are t...</td>\n",
       "      <td>Based on the retrieved documents, I couldn't f...</td>\n",
       "      <td>[254926669, 247315171, 182953113, 199552244, 4...</td>\n",
       "      <td>[258832652]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E5</td>\n",
       "      <td>Which paper proposed decomposing the logit upd...</td>\n",
       "      <td>few-shot</td>\n",
       "      <td>[254926669, 253761014, 247315171, 182953113, 1...</td>\n",
       "      <td>[Transformer-based large language models are t...</td>\n",
       "      <td>According to the retrieved documents, the pape...</td>\n",
       "      <td>[247315171]</td>\n",
       "      <td>[258832652]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>GRITLM</td>\n",
       "      <td>Could you recommend research that assesses tec...</td>\n",
       "      <td>few-shot</td>\n",
       "      <td>[235097394, 250390904, 247596835, 239015827, 2...</td>\n",
       "      <td>[The ease of access to pre-trained transformer...</td>\n",
       "      <td>Answer: Yes, there are several research papers...</td>\n",
       "      <td>[239015827, 260063038, 251928966, 259095603]</td>\n",
       "      <td>[237593027]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>GRITLM</td>\n",
       "      <td>Could you recommend research that assesses tec...</td>\n",
       "      <td>chain-of-thought</td>\n",
       "      <td>[235097394, 250390904, 247596835, 239015827, 2...</td>\n",
       "      <td>[The ease of access to pre-trained transformer...</td>\n",
       "      <td>To answer your question, let's break down the ...</td>\n",
       "      <td>[250390904, 251928966, 256105128]</td>\n",
       "      <td>[237593027]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>GRITLM</td>\n",
       "      <td>Which dataset supports narration generation an...</td>\n",
       "      <td>zero-shot</td>\n",
       "      <td>[253628210, 252624427, 258832605, 8994087, 223...</td>\n",
       "      <td>[This paper constructs a Chinese dialoguebased...</td>\n",
       "      <td>According to the retrieved documents, none of ...</td>\n",
       "      <td>[253628210, 258832605]</td>\n",
       "      <td>[258832605]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>GRITLM</td>\n",
       "      <td>Which dataset supports narration generation an...</td>\n",
       "      <td>few-shot</td>\n",
       "      <td>[253628210, 252624427, 258832605, 8994087, 223...</td>\n",
       "      <td>[This paper constructs a Chinese dialoguebased...</td>\n",
       "      <td>Answer: The dataset CMDQA supports narration g...</td>\n",
       "      <td>[253628210]</td>\n",
       "      <td>[258832605]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>GRITLM</td>\n",
       "      <td>Which dataset supports narration generation an...</td>\n",
       "      <td>chain-of-thought</td>\n",
       "      <td>[253628210, 252624427, 258832605, 8994087, 223...</td>\n",
       "      <td>[This paper constructs a Chinese dialoguebased...</td>\n",
       "      <td>Based on the given question, we will process i...</td>\n",
       "      <td>[253628210, 258832605, 2239496]</td>\n",
       "      <td>[258832605]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>540 rows √ó 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Retriever                                              Query  \\\n",
       "0          E5  Can you recommend research that uses an LLM to...   \n",
       "1          E5  Can you recommend research that uses an LLM to...   \n",
       "2          E5  Can you recommend research that uses an LLM to...   \n",
       "3          E5  Which paper proposed decomposing the logit upd...   \n",
       "4          E5  Which paper proposed decomposing the logit upd...   \n",
       "..        ...                                                ...   \n",
       "535    GRITLM  Could you recommend research that assesses tec...   \n",
       "536    GRITLM  Could you recommend research that assesses tec...   \n",
       "537    GRITLM  Which dataset supports narration generation an...   \n",
       "538    GRITLM  Which dataset supports narration generation an...   \n",
       "539    GRITLM  Which dataset supports narration generation an...   \n",
       "\n",
       "             Strategy                               Retrieved Corpus IDs  \\\n",
       "0           zero-shot  [258041372, 252716013, 260125086, 253098700, 2...   \n",
       "1            few-shot  [258041372, 252716013, 260125086, 253098700, 2...   \n",
       "2    chain-of-thought  [258041372, 252716013, 260125086, 253098700, 2...   \n",
       "3           zero-shot  [254926669, 253761014, 247315171, 182953113, 1...   \n",
       "4            few-shot  [254926669, 253761014, 247315171, 182953113, 1...   \n",
       "..                ...                                                ...   \n",
       "535          few-shot  [235097394, 250390904, 247596835, 239015827, 2...   \n",
       "536  chain-of-thought  [235097394, 250390904, 247596835, 239015827, 2...   \n",
       "537         zero-shot  [253628210, 252624427, 258832605, 8994087, 223...   \n",
       "538          few-shot  [253628210, 252624427, 258832605, 8994087, 223...   \n",
       "539  chain-of-thought  [253628210, 252624427, 258832605, 8994087, 223...   \n",
       "\n",
       "                                   Retrieved Abstracts  \\\n",
       "0    [Current literature demonstrates that Large La...   \n",
       "1    [Current literature demonstrates that Large La...   \n",
       "2    [Current literature demonstrates that Large La...   \n",
       "3    [Transformer-based large language models are t...   \n",
       "4    [Transformer-based large language models are t...   \n",
       "..                                                 ...   \n",
       "535  [The ease of access to pre-trained transformer...   \n",
       "536  [The ease of access to pre-trained transformer...   \n",
       "537  [This paper constructs a Chinese dialoguebased...   \n",
       "538  [This paper constructs a Chinese dialoguebased...   \n",
       "539  [This paper constructs a Chinese dialoguebased...   \n",
       "\n",
       "                                      Generated Answer  \\\n",
       "0    Based on the retrieved documents, here are som...   \n",
       "1    According to the retrieved documents, a resear...   \n",
       "2    Here's the breakdown of the question step by s...   \n",
       "3    Based on the retrieved documents, I couldn't f...   \n",
       "4    According to the retrieved documents, the pape...   \n",
       "..                                                 ...   \n",
       "535  Answer: Yes, there are several research papers...   \n",
       "536  To answer your question, let's break down the ...   \n",
       "537  According to the retrieved documents, none of ...   \n",
       "538  Answer: The dataset CMDQA supports narration g...   \n",
       "539  Based on the given question, we will process i...   \n",
       "\n",
       "                                      Cited Corpus IDs Ground Truth Corpus IDs  \n",
       "0    [252716013, 253098700, 264426355, 252596001, 2...             [229923710]  \n",
       "1                    [261696510, 248986239, 258558102]             [229923710]  \n",
       "2    [258041372, 252716013, 260125086, 253098700, 2...             [229923710]  \n",
       "3    [254926669, 247315171, 182953113, 199552244, 4...             [258832652]  \n",
       "4                                          [247315171]             [258832652]  \n",
       "..                                                 ...                     ...  \n",
       "535       [239015827, 260063038, 251928966, 259095603]             [237593027]  \n",
       "536                  [250390904, 251928966, 256105128]             [237593027]  \n",
       "537                             [253628210, 258832605]             [258832605]  \n",
       "538                                        [253628210]             [258832605]  \n",
       "539                    [253628210, 258832605, 2239496]             [258832605]  \n",
       "\n",
       "[540 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Results saved at: /data/horse/ws/uskh580e-myws/rag_results_e5_gtr_gritlm_10percent.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "from groq import Groq\n",
    "\n",
    "# ‚úÖ **Initialize Retrievers**\n",
    "retrievers = {\n",
    "    \"E5\": e5_retriever,\n",
    "    \"GTR\": gtr_retriever,\n",
    "    \"GRITLM\": grit_retriever\n",
    "}\n",
    "\n",
    "# ‚úÖ **Ensure Ground-Truth IDs are Correctly Formatted**\n",
    "query_df[\"corpusids\"] = query_df[\"corpusids\"].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "\n",
    "# ‚úÖ **Sample Only 10% of the Dataset**\n",
    "query_sample_df = query_df.sample(frac=0.10, random_state=42)  # Randomly select 10% of rows\n",
    "\n",
    "# ‚úÖ **Run Retrieval, Then Reformulate Query and Run RAG**\n",
    "rag_results = []\n",
    "\n",
    "for retriever_name, retriever in retrievers.items():\n",
    "    print(f\"\\nüöÄ Running Retrieval with {retriever_name} on 10% dataset...\\n\")\n",
    "\n",
    "    for _, row in tqdm(query_sample_df.iterrows(), total=len(query_sample_df), desc=f\"Retrieving with {retriever_name}\"):\n",
    "        original_query = row[\"query\"]\n",
    "        ground_truth_corpus_ids = row[\"corpusids\"]\n",
    "\n",
    "        # **Step 1: Retrieve First, Before Query Reformulation**\n",
    "        retrieved_ids = retriever.retrieve(original_query, k=20)\n",
    "        retrieved_ids_for_llm = retrieved_ids[:10]\n",
    "        \n",
    "        # **Fetch retrieved document details**\n",
    "        ranked_retrieved_df = pd.DataFrame({\"corpusid\": retrieved_ids})\n",
    "        retrieved_docs_info = ranked_retrieved_df.merge(\n",
    "            corpus_df[[\"corpusid\", \"title\", \"abstract\"]], \n",
    "            on=\"corpusid\", \n",
    "            how=\"left\"\n",
    "        )\n",
    "        retrieved_corpus_ids = retrieved_docs_info[\"corpusid\"].tolist()\n",
    "        retrieved_titles = retrieved_docs_info[\"title\"].tolist()\n",
    "        retrieved_abstracts = retrieved_docs_info[\"abstract\"].tolist()\n",
    "\n",
    "        # **Step 2: Reformulate Query AFTER Retrieval**\n",
    "        for strategy in [\"zero-shot\", \"few-shot\", \"chain-of-thought\"]:\n",
    "            modified_query = reformulate_query(original_query, strategy)\n",
    "\n",
    "            # **Step 3: Run LLM with Retrieved Documents**\n",
    "            generated_answer = generate_with_rag(original_query, modified_query, retrieved_ids_for_llm, retrieved_titles[:10], retrieved_abstracts[:10])\n",
    "\n",
    "            # **Step 4: Extract Cited Corpus IDs from LLM Response**\n",
    "            cited_corpus_ids = [str(doc_id) for doc_id in retrieved_ids_for_llm if str(doc_id) in generated_answer]\n",
    "\n",
    "            # **Step 5: Store Results**\n",
    "            rag_results.append({\n",
    "                \"Retriever\": retriever_name,\n",
    "                \"Query\": original_query,\n",
    "                \"Strategy\": strategy,\n",
    "                \"Retrieved Corpus IDs\": retrieved_corpus_ids,\n",
    "                \"Retrieved Abstracts\": retrieved_abstracts,\n",
    "                \"Generated Answer\": generated_answer,\n",
    "                \"Cited Corpus IDs\": cited_corpus_ids,\n",
    "                \"Ground Truth Corpus IDs\": ground_truth_corpus_ids\n",
    "            })\n",
    "\n",
    "# ‚úÖ Convert Results to DataFrame\n",
    "rag_results_df = pd.DataFrame(rag_results)\n",
    "\n",
    "# ‚úÖ Save Results\n",
    "RAG_RESULTS_PATH = os.path.join(WORKSPACE_PATH, \"rag_results_e5_gtr_gritlm_10percent.csv\")\n",
    "rag_results_df.to_csv(RAG_RESULTS_PATH, index=False)\n",
    "display(rag_results_df)\n",
    "\n",
    "print(f\"‚úÖ Results saved at: {RAG_RESULTS_PATH}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f60333c1-432b-4af4-aca1-b2654a9e5297",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAG_RESULTS_PATH = os.path.join(WORKSPACE_PATH, \"rag_results_e5_gtr_gritlm_10percent.csv\")\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "rag_results_df = pd.read_csv(RAG_RESULTS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9e15e36a-5b1b-488d-be0a-52f89cd1b1a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Retriever</th>\n",
       "      <th>Query</th>\n",
       "      <th>Strategy</th>\n",
       "      <th>Retrieved Corpus IDs</th>\n",
       "      <th>Retrieved Abstracts</th>\n",
       "      <th>Generated Answer</th>\n",
       "      <th>Cited Corpus IDs</th>\n",
       "      <th>Ground Truth Corpus IDs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E5</td>\n",
       "      <td>Can you recommend research that uses an LLM to...</td>\n",
       "      <td>zero-shot</td>\n",
       "      <td>[258041372, 252716013, 260125086, 253098700, 2...</td>\n",
       "      <td>['Current literature demonstrates that Large L...</td>\n",
       "      <td>Based on the retrieved documents, here are som...</td>\n",
       "      <td>['252716013', '253098700', '264426355', '25259...</td>\n",
       "      <td>[229923710]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E5</td>\n",
       "      <td>Can you recommend research that uses an LLM to...</td>\n",
       "      <td>few-shot</td>\n",
       "      <td>[258041372, 252716013, 260125086, 253098700, 2...</td>\n",
       "      <td>['Current literature demonstrates that Large L...</td>\n",
       "      <td>According to the retrieved documents, a resear...</td>\n",
       "      <td>['261696510', '248986239', '258558102']</td>\n",
       "      <td>[229923710]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E5</td>\n",
       "      <td>Can you recommend research that uses an LLM to...</td>\n",
       "      <td>chain-of-thought</td>\n",
       "      <td>[258041372, 252716013, 260125086, 253098700, 2...</td>\n",
       "      <td>['Current literature demonstrates that Large L...</td>\n",
       "      <td>Here's the breakdown of the question step by s...</td>\n",
       "      <td>['258041372', '252716013', '260125086', '25309...</td>\n",
       "      <td>[229923710]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E5</td>\n",
       "      <td>Which paper proposed decomposing the logit upd...</td>\n",
       "      <td>zero-shot</td>\n",
       "      <td>[254926669, 253761014, 247315171, 182953113, 1...</td>\n",
       "      <td>['Transformer-based large language models are ...</td>\n",
       "      <td>Based on the retrieved documents, I couldn't f...</td>\n",
       "      <td>['254926669', '247315171', '182953113', '19955...</td>\n",
       "      <td>[258832652]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E5</td>\n",
       "      <td>Which paper proposed decomposing the logit upd...</td>\n",
       "      <td>few-shot</td>\n",
       "      <td>[254926669, 253761014, 247315171, 182953113, 1...</td>\n",
       "      <td>['Transformer-based large language models are ...</td>\n",
       "      <td>According to the retrieved documents, the pape...</td>\n",
       "      <td>['247315171']</td>\n",
       "      <td>[258832652]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Retriever                                              Query  \\\n",
       "0        E5  Can you recommend research that uses an LLM to...   \n",
       "1        E5  Can you recommend research that uses an LLM to...   \n",
       "2        E5  Can you recommend research that uses an LLM to...   \n",
       "3        E5  Which paper proposed decomposing the logit upd...   \n",
       "4        E5  Which paper proposed decomposing the logit upd...   \n",
       "\n",
       "           Strategy                               Retrieved Corpus IDs  \\\n",
       "0         zero-shot  [258041372, 252716013, 260125086, 253098700, 2...   \n",
       "1          few-shot  [258041372, 252716013, 260125086, 253098700, 2...   \n",
       "2  chain-of-thought  [258041372, 252716013, 260125086, 253098700, 2...   \n",
       "3         zero-shot  [254926669, 253761014, 247315171, 182953113, 1...   \n",
       "4          few-shot  [254926669, 253761014, 247315171, 182953113, 1...   \n",
       "\n",
       "                                 Retrieved Abstracts  \\\n",
       "0  ['Current literature demonstrates that Large L...   \n",
       "1  ['Current literature demonstrates that Large L...   \n",
       "2  ['Current literature demonstrates that Large L...   \n",
       "3  ['Transformer-based large language models are ...   \n",
       "4  ['Transformer-based large language models are ...   \n",
       "\n",
       "                                    Generated Answer  \\\n",
       "0  Based on the retrieved documents, here are som...   \n",
       "1  According to the retrieved documents, a resear...   \n",
       "2  Here's the breakdown of the question step by s...   \n",
       "3  Based on the retrieved documents, I couldn't f...   \n",
       "4  According to the retrieved documents, the pape...   \n",
       "\n",
       "                                    Cited Corpus IDs Ground Truth Corpus IDs  \n",
       "0  ['252716013', '253098700', '264426355', '25259...             [229923710]  \n",
       "1            ['261696510', '248986239', '258558102']             [229923710]  \n",
       "2  ['258041372', '252716013', '260125086', '25309...             [229923710]  \n",
       "3  ['254926669', '247315171', '182953113', '19955...             [258832652]  \n",
       "4                                      ['247315171']             [258832652]  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "24f3d43c-a1f7-46bf-8648-e0eaf2092267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Retriever</th>\n",
       "      <th>Strategy</th>\n",
       "      <th>Recall@5</th>\n",
       "      <th>Recall@20</th>\n",
       "      <th>Citation Precision</th>\n",
       "      <th>Citation Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E5</td>\n",
       "      <td>chain-of-thought</td>\n",
       "      <td>0.471784</td>\n",
       "      <td>0.813060</td>\n",
       "      <td>0.652059</td>\n",
       "      <td>0.912553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E5</td>\n",
       "      <td>few-shot</td>\n",
       "      <td>0.471784</td>\n",
       "      <td>0.813060</td>\n",
       "      <td>0.685563</td>\n",
       "      <td>0.826667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E5</td>\n",
       "      <td>zero-shot</td>\n",
       "      <td>0.471784</td>\n",
       "      <td>0.813060</td>\n",
       "      <td>0.659065</td>\n",
       "      <td>0.885608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GRITLM</td>\n",
       "      <td>chain-of-thought</td>\n",
       "      <td>0.458734</td>\n",
       "      <td>0.834072</td>\n",
       "      <td>0.611840</td>\n",
       "      <td>0.947063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GRITLM</td>\n",
       "      <td>few-shot</td>\n",
       "      <td>0.458734</td>\n",
       "      <td>0.834072</td>\n",
       "      <td>0.662170</td>\n",
       "      <td>0.925575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GRITLM</td>\n",
       "      <td>zero-shot</td>\n",
       "      <td>0.458734</td>\n",
       "      <td>0.834072</td>\n",
       "      <td>0.680844</td>\n",
       "      <td>0.919967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GTR</td>\n",
       "      <td>chain-of-thought</td>\n",
       "      <td>0.413363</td>\n",
       "      <td>0.765863</td>\n",
       "      <td>0.626151</td>\n",
       "      <td>0.914028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GTR</td>\n",
       "      <td>few-shot</td>\n",
       "      <td>0.413363</td>\n",
       "      <td>0.765863</td>\n",
       "      <td>0.663481</td>\n",
       "      <td>0.847228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GTR</td>\n",
       "      <td>zero-shot</td>\n",
       "      <td>0.413363</td>\n",
       "      <td>0.765863</td>\n",
       "      <td>0.669551</td>\n",
       "      <td>0.863161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Retriever          Strategy  Recall@5  Recall@20  Citation Precision  \\\n",
       "0        E5  chain-of-thought  0.471784   0.813060            0.652059   \n",
       "1        E5          few-shot  0.471784   0.813060            0.685563   \n",
       "2        E5         zero-shot  0.471784   0.813060            0.659065   \n",
       "3    GRITLM  chain-of-thought  0.458734   0.834072            0.611840   \n",
       "4    GRITLM          few-shot  0.458734   0.834072            0.662170   \n",
       "5    GRITLM         zero-shot  0.458734   0.834072            0.680844   \n",
       "6       GTR  chain-of-thought  0.413363   0.765863            0.626151   \n",
       "7       GTR          few-shot  0.413363   0.765863            0.663481   \n",
       "8       GTR         zero-shot  0.413363   0.765863            0.669551   \n",
       "\n",
       "   Citation Recall  \n",
       "0         0.912553  \n",
       "1         0.826667  \n",
       "2         0.885608  \n",
       "3         0.947063  \n",
       "4         0.925575  \n",
       "5         0.919967  \n",
       "6         0.914028  \n",
       "7         0.847228  \n",
       "8         0.863161  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Metrics saved at: /data/horse/ws/uskh580e-myws/retrieval_metrics_e5_gtr_gritlm_fixed.csv\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Compute retrieval and citation metrics with debugging\n",
    "def compute_metrics(row):\n",
    "    retrieved_corpus_ids = set(row[\"Retrieved Corpus IDs\"][:20])  # Top-20 retrieved documents\n",
    "    ground_truth_corpus_ids = set(row[\"Ground Truth Corpus IDs\"])\n",
    "    cited_corpus_ids = set(row[\"Cited Corpus IDs\"])\n",
    "\n",
    "    # ‚úÖ Debugging: Print if there's a mismatch\n",
    "    if not retrieved_corpus_ids & ground_truth_corpus_ids:\n",
    "        print(f\"‚ö†Ô∏è No Overlap Detected for Query: {row['Query']}\")\n",
    "        print(f\"Retrieved: {retrieved_corpus_ids}\")\n",
    "        print(f\"Ground Truth: {ground_truth_corpus_ids}\\n\")\n",
    "\n",
    "    if not ground_truth_corpus_ids:\n",
    "        return pd.Series([0.0, 0.0, 0.0, 0.0], index=[\"Recall@5\", \"Recall@20\", \"Citation Precision\", \"Citation Recall\"])\n",
    "\n",
    "    tp_retrieved_5 = len(set(row[\"Retrieved Corpus IDs\"][:5]) & ground_truth_corpus_ids)\n",
    "    tp_retrieved_20 = len(retrieved_corpus_ids & ground_truth_corpus_ids)\n",
    "    tp_cited = len(cited_corpus_ids & ground_truth_corpus_ids)\n",
    "\n",
    "    recall_5 = tp_retrieved_5 / len(ground_truth_corpus_ids) if ground_truth_corpus_ids else 0.0\n",
    "    recall_20 = tp_retrieved_20 / len(ground_truth_corpus_ids) if ground_truth_corpus_ids else 0.0\n",
    "    citation_precision = tp_cited / len(cited_corpus_ids) if cited_corpus_ids else 0.0\n",
    "    citation_recall = tp_cited / len(ground_truth_corpus_ids) if ground_truth_corpus_ids else 0.0\n",
    "\n",
    "    return pd.Series([recall_5, recall_20, citation_precision, citation_recall], \n",
    "                     index=[\"Recall@5\", \"Recall@20\", \"Citation Precision\", \"Citation Recall\"])\n",
    "\n",
    "# ‚úÖ Apply function\n",
    "rag_results_df[[\"Recall@5\", \"Recall@20\", \"Citation Precision\", \"Citation Recall\"]] = rag_results_df.apply(compute_metrics, axis=1)\n",
    "\n",
    "# ‚úÖ Aggregate metrics per strategy and retriever\n",
    "metrics_summary = rag_results_df.groupby([\"Retriever\", \"Strategy\"])[\n",
    "    [\"Recall@5\", \"Recall@20\", \"Citation Precision\", \"Citation Recall\"]\n",
    "].mean().reset_index()\n",
    "\n",
    "# ‚úÖ Display final table\n",
    "display(metrics_summary)\n",
    "\n",
    "# ‚úÖ Save to CSV\n",
    "METRICS_RESULTS_PATH = os.path.join(WORKSPACE_PATH, \"retrieval_metrics_e5_gtr_gritlm_fixed.csv\")\n",
    "metrics_summary.to_csv(METRICS_RESULTS_PATH, index=False)\n",
    "\n",
    "print(f\"‚úÖ Metrics saved at: {METRICS_RESULTS_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e166fa34-81ab-4150-8b07-42de91207918",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Generated Answer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/data/horse/ws/uskh580e-llm_citation_ws/myenv/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Generated Answer'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Print a sample answer to debug\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerated Answer:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGenerated Answer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCited IDs:\u001b[39m\u001b[38;5;124m\"\u001b[39m, row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCited Corpus IDs\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m/data/horse/ws/uskh580e-llm_citation_ws/myenv/lib/python3.10/site-packages/pandas/core/series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m/data/horse/ws/uskh580e-llm_citation_ws/myenv/lib/python3.10/site-packages/pandas/core/series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1237\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m/data/horse/ws/uskh580e-llm_citation_ws/myenv/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Generated Answer'"
     ]
    }
   ],
   "source": [
    "# Print a sample answer to debug\n",
    "print(\"Generated Answer:\", row[\"Generated Answer\"])\n",
    "print(\"Cited IDs:\", row[\"Cited Corpus IDs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c80239d7-47fe-423d-b80f-211f819f673e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample retrieved IDs: [2239496, 253098734, 252624427, 253628210, 258832605]\n",
      "Sample ground truth IDs: [258832605]\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample retrieved IDs:\", retrieved_corpus_ids[:5])\n",
    "print(\"Sample ground truth IDs:\", ground_truth_corpus_ids[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a318f947-d998-49a1-b363-27944f5d11c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data from query_df:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>corpusids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Are there any research papers on methods to co...</td>\n",
       "      <td>[202719327]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Are there any resources available for translat...</td>\n",
       "      <td>[227231792]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Are there any studies that explore post-hoc te...</td>\n",
       "      <td>[226254579, 204976362]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Are there any tools or studies that have focus...</td>\n",
       "      <td>[10961392, 12160022]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Are there papers that propose contextualized c...</td>\n",
       "      <td>[233296182]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Are there studies that combine convolutional a...</td>\n",
       "      <td>[17297069]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Can you direct me to research that explores me...</td>\n",
       "      <td>[174801080]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Can you direct me to studies that explore tech...</td>\n",
       "      <td>[247593812]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Can you list some publications that discuss th...</td>\n",
       "      <td>[561429, 17553490, 16509032]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Can you point me to a paper that discussed tra...</td>\n",
       "      <td>[201646309]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  Are there any research papers on methods to co...   \n",
       "1  Are there any resources available for translat...   \n",
       "2  Are there any studies that explore post-hoc te...   \n",
       "3  Are there any tools or studies that have focus...   \n",
       "4  Are there papers that propose contextualized c...   \n",
       "5  Are there studies that combine convolutional a...   \n",
       "6  Can you direct me to research that explores me...   \n",
       "7  Can you direct me to studies that explore tech...   \n",
       "8  Can you list some publications that discuss th...   \n",
       "9  Can you point me to a paper that discussed tra...   \n",
       "\n",
       "                      corpusids  \n",
       "0                   [202719327]  \n",
       "1                   [227231792]  \n",
       "2        [226254579, 204976362]  \n",
       "3          [10961392, 12160022]  \n",
       "4                   [233296182]  \n",
       "5                    [17297069]  \n",
       "6                   [174801080]  \n",
       "7                   [247593812]  \n",
       "8  [561429, 17553490, 16509032]  \n",
       "9                   [201646309]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Sample data from query_df:\")\n",
    "display(query_df[[\"query\", \"corpusids\"]].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "60593f8f-1114-4c63-b293-43792b98f107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üö® 540 out of 540 rows have empty Ground Truth Corpus IDs!\n",
      "‚ö†Ô∏è This means 100.0% of rows are missing ground truth data.\n"
     ]
    }
   ],
   "source": [
    "# Check how many rows have empty ground truth corpus IDs\n",
    "empty_ground_truth = rag_results_df[\"Ground Truth Corpus IDs\"].apply(lambda x: len(x) == 0).sum()\n",
    "total_rows = len(rag_results_df)\n",
    "\n",
    "print(f\"üö® {empty_ground_truth} out of {total_rows} rows have empty Ground Truth Corpus IDs!\")\n",
    "print(f\"‚ö†Ô∏è This means {round((empty_ground_truth / total_rows) * 100, 2)}% of rows are missing ground truth data.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e7154e-ab58-4a67-80a9-a1f4796884e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
